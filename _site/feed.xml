<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-07-21T22:12:15+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">A life that made sense</title><subtitle>My family and I took a road less traveled. This blog will be a journal concerning our new life in France. I hope to share some fun engineering projects also along the way.</subtitle><author><name>Mike Hinkle</name></author><entry><title type="html">A simple use case for dbt and Airflow</title><link href="http://localhost:4000/rpi/postgres/dbt/airflow/2021/07/20/dbt_install_transform.html" rel="alternate" type="text/html" title="A simple use case for dbt and Airflow" /><published>2021-07-20T17:00:00+02:00</published><updated>2021-07-20T17:00:00+02:00</updated><id>http://localhost:4000/rpi/postgres/dbt/airflow/2021/07/20/dbt_install_transform</id><content type="html" xml:base="http://localhost:4000/rpi/postgres/dbt/airflow/2021/07/20/dbt_install_transform.html">&lt;p&gt;My previous two posts involved installing a postgres server on a cheap, spare raspberry pi 3b+.
The motivation was to save my time-series data for longer than 30-days since my free InfluxDB Cloud
account, only has a 30-day retention policy.&lt;/p&gt;

&lt;p&gt;I was successful in installing a fresh OS, configuring the &lt;strong&gt;rpi&lt;/strong&gt; to run headless, scanning the local
ip’s to find the rpi, ssh’ing to the single board computer, installing a &lt;strong&gt;PostgreSQL&lt;/strong&gt; instance and
finally writing a script to query my influxDB instance, transform the data and push the data to my
postgresql database. I used a cronjob to execute the script with a comment about accomplishing
the same task using &lt;strong&gt;Apache Airflow&lt;/strong&gt;. So today, I am back to offload the scheduling from the cron daemon
to Airflow and I am also throwing a &lt;strong&gt;dbt&lt;/strong&gt; incremental materialization into the mix.&lt;/p&gt;

&lt;h3 id=&quot;motivation-for-added-complexity&quot;&gt;Motivation for added complexity&lt;/h3&gt;

&lt;p&gt;You might say that the cronjob was working just fine and if it isn’t broken, why fix it :wrench: ? I
even commented during the writing that using Airflow felt like bird hunting with a scud missile. 
Despite my comment, I have a simple and good reason to make use of Airflow.&lt;/p&gt;

&lt;p&gt;The pulse oximeter data 
I am collecting is very noisy. More so when my daughter moves, the sensor is not attached well or 
the sensor could even be defective. Whatever the case may be, outliers are not uncommon. Here is
a screenshot to illustrate my point. The orange trace below represents the mean over a five second
rolling window of my daughter’s heartrate. So, these data have already been “smoothed” slightly
considering I capture her &lt;strong&gt;heartrate&lt;/strong&gt;, &lt;strong&gt;specific oxygen&lt;/strong&gt; and &lt;strong&gt;perfusion index&lt;/strong&gt; all at a frequency of one 
sample per second.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/bpm_five_sec_agg.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I would like to smooth the signal even more using something simple like a moving average. This
would allow me to more easily spot trends. Since I look at my daughter’s trends regularly, I need
the data to be relatively up-to-date. I also take snapshots from my cloud database on an
hourly basis, so it would be nice to calculate a moving average for my metrics of interest at the
same time and frequency the updates occur. In this spirit, I decided to use dbt (&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;B&lt;/strong&gt;uild &lt;strong&gt;T&lt;/strong&gt;ool) to perform the
transformation and materialization, and Airflow to ensure that this dbt model runs after and only
after the data is loaded into postgresql from my cloud instance. So, let’s get started.&lt;/p&gt;

&lt;h2 id=&quot;dbt-install-init-model-creation-and-test&quot;&gt;dbt: Install, init, model creation and test&lt;/h2&gt;

&lt;p&gt;I will not delve into all of the fine details of dbt, the &lt;a href=&quot;https://docs.getdbt.com/docs/introduction&quot;&gt;documentation&lt;/a&gt;
found online is excellent and I encourage you if you are interested in databases to check it out yourself.
I will say that dbt will allow me to easily perform a transformation on data in my postgresql database using
a simple query. After the transformation has been performed, dbt will handle the materialization for me.&lt;/p&gt;

&lt;h3 id=&quot;dbt-install-and-initialization&quot;&gt;dbt: Install and initialization&lt;/h3&gt;

&lt;p&gt;Dbt is a python module and can therefore be installed with pip. Using &lt;em&gt;pip&lt;/em&gt; I installed dbt-postgres
on my rpi3b+: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python3 -m pip install dbt-postgres&lt;/code&gt;. I specified PostgreSQL because I am
transforming data on a postgres server and dbt will need the postgres adapter to interact with the
database. Some other supported databases include: BigQuery, Redshift and Snowflake.&lt;/p&gt;

&lt;p&gt;After the install was complete, I initialized a project called &lt;strong&gt;health_metrics&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ dbt init health_metrics --adapter postgres
Running with dbt=0.20.0
Creating dbt configuration folder at /home/pi/.dbt
With sample profiles.yml for postgres

Your new dbt project &quot;health_metrics&quot; was created! If this is your first time
using dbt, you'll need to set up your profiles.yml file (we've created a sample
file for you to connect to postgres) -- this file will tell dbt how
to connect to your database. You can find this file by running:

  xdg-open /home/pi/.dbt

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack --
There's a link to our Slack group in the GitHub Readme. Happy modeling!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, I need to update the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;profiles.yml&lt;/code&gt; file as indicated by the message above
seen after initilizing my dbt project. Below shows my updated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;profiles.yml&lt;/code&gt; file
with the database password excluded:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  
    &lt;span class=&quot;na&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;postgres&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.12&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5432&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;soitgoes511&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pass&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;PASSW_OF_DB&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pulse_oximeter_historic&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;public&lt;/span&gt;
      
    &lt;span class=&quot;na&quot;&gt;prod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;postgres&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;threads&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;192.168.0.12&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5432&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;soitgoes511&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;pass&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;PASSW_OF_DB&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;dbname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pulse_oximeter_historic&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;public&lt;/span&gt;
    
  &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;dev&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;profiles.yml&lt;/code&gt; configuration has been completed, I can save the file
and move on to writing the actual model.&lt;/p&gt;

&lt;h3 id=&quot;dbt-model-creation-and-test&quot;&gt;dbt: Model creation and test&lt;/h3&gt;

&lt;p&gt;A model in it’s most basic form is an &lt;strong&gt;.sql&lt;/strong&gt; file containing a single SQL 
&lt;strong&gt;SELECT&lt;/strong&gt; statement. Included in the same directory as the &lt;strong&gt;.sql&lt;/strong&gt; file is a
file named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.yml&lt;/code&gt; containing the model name, the column names being 
returned by the &lt;strong&gt;SELECT&lt;/strong&gt; statement, a brief description of each column and
test assertions which can be used to validate your model is performing the way
you expect it to. Further down the road, your model can be tested simply
by executing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dbt test&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;So, to the task at hand. I wanted to remove some noise and smooth my data
and will start by calculating a simple moving average. My original data
has been aggregated using the mean over a five second window before it is loaded 
into my postgresql database. This means I should have 12 samples per minute.
I have been looking at pulse oximeter data for years now and feel confident
that a five minute window will remove most of the noise without losing too
much information. I can always adjust later, or revert back to my 5 second
aggregated data. No harm, no foul. So, 12 samples per minute for 5 minutes
equates to 60 data points (I need this for my query below).&lt;/p&gt;

&lt;p&gt;One more point to cover before getting to the actual query/model. Dbt supports
templating, macros, references, etc.. The possible materializations include
a table, view, incremental and ephemeral. &lt;strong&gt;Table&lt;/strong&gt; and &lt;strong&gt;View&lt;/strong&gt; are hopefully
self-explanatory. If not, please refer to the documentation link I referenced
earlier in this writing. I will be using &lt;strong&gt;incremental&lt;/strong&gt;. Incremental for the
first execution will build a complete table. For later model runs,
dbt will only build the new data onto the table assuming I have the &lt;strong&gt;is_incremental()&lt;/strong&gt;
macro wrapping my filters used to specify the new data. Again, the dbt folks do a much better 
job explaining this and that explanation can be found 
&lt;a href=&quot;https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, here is the first iteration of my moving average model which will build
a table, incrementally (completely at first and can be rebuilt anew if
the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--full-refresh&lt;/code&gt; flag is used at runtime):&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;materialized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'incremental'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;spo2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spo2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;59&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PRECEDING&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROW&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_spo2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;bpm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bpm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;59&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PRECEDING&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROW&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_bpm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;perf_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;AVG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perf_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;59&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PRECEDING&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ROW&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma_perf&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pox_five_second_mean&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_incremental&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The contents of my &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schema.yml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;pulse_ox_moving_average&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;minute&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;spo2,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bpm&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;perf&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;time&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;primary&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;table&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;spo2&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SPO2&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sensor&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;aggregated&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;minutes&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;series&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ma_spo2&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Minute&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SPO2,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;previous&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;current&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bpm&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BPM&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sensor&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;aggregated&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;minutes&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;series&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ma_bpm&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Minute&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BPM,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;previous&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;current&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;perf_index&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Perfusion&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Index&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sensor&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;aggregated&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;minutes&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;series&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ma_perf&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Minute&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;moving&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;of&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Perfusion&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Index,&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;previous&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;current&quot;&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;not_null&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And finally, let me run the model and see what happens:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ dbt run
Running with dbt=0.20.0
Found 1 model, 7 tests, 0 snapshots, 0 analyses, 147 macros, 0 operations, 0 seed files, 0 sources, 0 exposures

22:45:55 | Concurrency: 1 threads (target='dev')
22:45:55 |
22:45:55 | 1 of 1 START incremental model public.pulse_ox_moving_average........ [RUN]
22:45:56 | 1 of 1 OK created incremental model public.pulse_ox_moving_average... [INSERT 0 0 in 0.84s]
22:45:56 |
22:45:56 | Finished running 1 incremental model in 1.41s.

Completed successfully

Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Notice the relatively fast time of execution. That is because I have run this model before and there is no new
data loaded to compute the moving average. The actual runtime is about 22 seconds, please bare in mind this is an
oldish rpi3b+ and not a supercomputer. Also note, that if I had specified a &lt;strong&gt;table&lt;/strong&gt; for my materialization,
the entire table would have been rebuilt and this would have taken even longer than 22 seconds. If I were
using a pay-per-use cloud provider, that would most likely equate to money down the drain :money_with_wings: . Here is a sample of the
result of my successful model materialization:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ma_post_test.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now that the model is working and has been tested, it is time to automate the model run at the top of each hour.
Let’s move onto setting up Apache Airflow and creating a DAG (&lt;strong&gt;D&lt;/strong&gt;irected &lt;strong&gt;A&lt;/strong&gt;cyclic &lt;strong&gt;G&lt;/strong&gt;raph).&lt;/p&gt;

&lt;h2 id=&quot;apache-airflow-install-setup-and-dag-creation&quot;&gt;Apache Airflow: Install, setup and DAG creation&lt;/h2&gt;

&lt;p&gt;Airflow was created by Maxime Beauchemin and used at Airbnb in 2014 to programmatically schedule tasks. Since
that time, Airflow has become a part of the Apache Software Foundation.&lt;/p&gt;

&lt;p&gt;I decided to change from my simplistic cron schedular to Airflow to ensure that the moving average is not
calculated until after the pulse oximeter data has been retrieved from my InfluxDB instance, shaped and
loaded into the PostgreSQL database server running on my raspberry pi. I could have handled this with
a cronjob in quite a few ways (e.g. Serializing the data extraction and loading with the moving average
calculation and table creation in the same script or simply by skewing the timing of two different
crons which is an error prone hack imho). While this is a simplistic use case, it still
solves my script execution timing issue in an elegant manner (with some added complexity). :grin:&lt;/p&gt;

&lt;h3 id=&quot;airflow-install-and-setup&quot;&gt;Airflow: Install and setup&lt;/h3&gt;

&lt;p&gt;I used the following steps to install Airflow on my raspberry pi. Please be aware that these steps were
taken directly from the Apache Airflow docs which can be found &lt;a href=&quot;https://airflow.apache.org/docs/apache-airflow/stable/start/local.html&quot;&gt;here&lt;/a&gt;.
I have not altered nor improved these steps in any way and in no way am taking any credit for this:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# airflow needs a home, ~/airflow is the default,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# but you can lay foundation somewhere else if you prefer&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# (optional)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;~/airflow

&lt;span class=&quot;nv&quot;&gt;AIRFLOW_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2.1.2
&lt;span class=&quot;nv&quot;&gt;PYTHON_VERSION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;python &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 2 | &lt;span class=&quot;nb&quot;&gt;cut&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; 1-2&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# For example: 3.6&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;CONSTRAINT_URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://raw.githubusercontent.com/apache/airflow/constraints-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;AIRFLOW_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/constraints-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PYTHON_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.txt&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# For example: https://raw.githubusercontent.com/apache/airflow/constraints-2.1.2/constraints-3.6.txt&lt;/span&gt;
pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;apache-airflow==&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;AIRFLOW_VERSION&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--constraint&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CONSTRAINT_URL&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# initialize the database&lt;/span&gt;
airflow db init

airflow &lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;create &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; admin &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--firstname&lt;/span&gt; Peter &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--lastname&lt;/span&gt; Parker &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--role&lt;/span&gt; Admin &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--email&lt;/span&gt; spiderman@superhero.org

&lt;span class=&quot;c&quot;&gt;# start the web server, default port is 8080&lt;/span&gt;
airflow webserver &lt;span class=&quot;nt&quot;&gt;--port&lt;/span&gt; 8080

&lt;span class=&quot;c&quot;&gt;# start the scheduler&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# open a new terminal or else run webserver with ``-D`` option to run it as a daemon&lt;/span&gt;
airflow scheduler

&lt;span class=&quot;c&quot;&gt;# visit localhost:8080 in the browser and use the admin account you just&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# created to login. Enable the example_bash_operator dag in the home page&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the installation is complete, I ensured to make all necessary changes
to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;airflow.cfg&lt;/code&gt; located at ~/airflow/ (which in my case was /home/pi/airflow/).
The primary setting I needed to know was where my DAGs where located. This setting
is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dags_folder = /home/pi/airflow/dags&lt;/code&gt; in my case. This is where my DAG (&lt;strong&gt;.py&lt;/strong&gt; files
will go). I also did not adjust the &lt;strong&gt;default_timezone&lt;/strong&gt;. I used &lt;strong&gt;utc&lt;/strong&gt; time as I did 
for my PostgreSQL instance and as I would recommend anyone reading this should do.
Timezones have caused me some real headaches over the years and I find the best practice
to be, storing all data using UTC timestamps and then handling the timezones on the
application end if necessary.&lt;/p&gt;

&lt;h3 id=&quot;airflow-dag-creation&quot;&gt;Airflow: DAG creation&lt;/h3&gt;

&lt;p&gt;A DAG is a Directed Acyclic Graph as I have already mentioned. Put simply, it is a graph
who’s nodes are tasks. Those tasks are connected from one node to the next and the
overall graph contains no closed loop. This screenshot of my DAG taken from the
Airflow webserver should clarify the &lt;em&gt;Graph&lt;/em&gt; concept. My tasks are the nodes and the overall
graph is the name of my DAG. Notice there is directionality illustrated by an arrow pointing
from &lt;strong&gt;load_pg_from_influx&lt;/strong&gt; :arrow_right: &lt;strong&gt;moving_average_calc&lt;/strong&gt;. Therefore, the moving average task will
be executed after the loading of data to postgres task is complete:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/airflow_graph.jpg&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Below is my DAG located in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/home/pi/airflow/dags/&lt;/code&gt;. I used two operators for the two
different tasks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;dbt_operator - (from pkg &lt;strong&gt;airflow-dbt&lt;/strong&gt; in PyPi) which makes it easy to execute my dbt model&lt;/li&gt;
  &lt;li&gt;BashOperator - which allows me to execute commands in Bash shell&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have set the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;schedule_interval&lt;/code&gt; to run at the top of each hour, every hour of every day. This
should be familiar to those that have scheduled a cronjob before… I can use the same syntax.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DAG&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow_dbt.operators.dbt_operator&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DbtRunOperator&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow.operators.bash&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BashOperator&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow.utils.dates&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;days_ago&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'dir'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'/home/pi/dbt_world/health_metrics'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'start_date'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;days_ago&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DAG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pulse_ox_data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_interval&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'0 * * * *'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;influx_pg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BashOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'load_pg_from_influx'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bash_command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/usr/bin/python3 /home/pi/pg_loader/health_metrics_loader.py'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dbt_run&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DbtRunOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'moving_average_calc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;influx_pg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbt_run&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please note the task variable influx_pg pipes into the dbt_run variable in the above script/DAG. This defines my
graph directionality and order of execution. If I decide at some later point in time that
I would like to materialize another view or table from the original influx_pg data, I can
pipe into a list object (e.g. &lt;strong&gt;t1 » [t2, t3]&lt;/strong&gt;). Like I said, what I have done so far
is not very complex. Despite not being very complex, I was able to solve my scheduling dilemma
in an elegant manner. If this were some critical data pipeline, I could send emails to myself
or my team if my tasks fail. Airflow gives much more information and ability than a vanilla cronjob
would to allow for troubleshooting efficiencies, bottlenecks or failures.&lt;/p&gt;

&lt;p&gt;Last but not least, here is a screenshot of the resulting moving average (blue) for my daughter’s heartrate
overlayed onto the original heartrate data stored in my PostgreSQL database (orange):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ma_bpm.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If someone reads this and spots an obvious mistake or has some additional insights or questions,
please send me an email.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I don’t know what is behind the curtain; only that I need to find out.”
― Richard Paul Evans, Lost December&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Mike Hinkle</name></author><category term="rpi" /><category term="postgres" /><category term="dbt" /><category term="airflow" /><summary type="html">My previous two posts involved installing a postgres server on a cheap, spare raspberry pi 3b+. The motivation was to save my time-series data for longer than 30-days since my free InfluxDB Cloud account, only has a 30-day retention policy.</summary></entry><entry><title type="html">Extract, transform &amp;amp; load: InfluxDB Cloud to Local PostgreSQL (Part 2)</title><link href="http://localhost:4000/rpi/influxdb/postgresql/etl/cronjob/2021/07/12/influx_to_postgres.html" rel="alternate" type="text/html" title="Extract, transform &amp;amp; load: InfluxDB Cloud to Local PostgreSQL (Part 2)" /><published>2021-07-12T17:00:00+02:00</published><updated>2021-07-12T17:00:00+02:00</updated><id>http://localhost:4000/rpi/influxdb/postgresql/etl/cronjob/2021/07/12/influx_to_postgres</id><content type="html" xml:base="http://localhost:4000/rpi/influxdb/postgresql/etl/cronjob/2021/07/12/influx_to_postgres.html">&lt;h3 id=&quot;quick-recap&quot;&gt;Quick Recap&lt;/h3&gt;

&lt;p&gt;During part 1, I walked through the following actions in the effort
to keep my cloud storage data for a longer duration:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Burning a new OS image to a microSD&lt;/li&gt;
  &lt;li&gt;Setting up a raspberry pi 3b+ to run headless&lt;/li&gt;
  &lt;li&gt;Installing and configuring a postgresql server on the rpi&lt;/li&gt;
  &lt;li&gt;Testing the postgresql instance by writing data to it remotely&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This probably sounds backwards, if you did not read 
&lt;a href=&quot;https://soitgoes511.github.io/rpi/headless/postgresql/2021/07/10/rpi_headless_postgres.html&quot;&gt;part 1&lt;/a&gt;, 
but to recap, I don’t pay for my InfluxDB cloud account and have a 30-day 
retention policy on my data storage. 30-days is fine for real-time
monitoring but for longer term modeling, I have installed a postgreSQL
database on an oldish raspberry pi 3b+ and aim to collect longintudinal 
health metrics. So, without further ado…&lt;/p&gt;

&lt;h3 id=&quot;extract-transform-and-load&quot;&gt;Extract, Transform and Load&lt;/h3&gt;

&lt;p&gt;First, I would like to offer an explanation as to why I have decided to not store the data 
on a local instance of InfluxDB and then I will give some insight into the data I have stored 
on the cloud, the structure of the data and the resolution. Finally, I will share the script
I will be using to perform the ETL operation.&lt;/p&gt;

&lt;h4 id=&quot;why-postgres-rather-than-a-local-influxdb-instance&quot;&gt;Why postgres rather than a local influxdb instance?&lt;/h4&gt;

&lt;p&gt;Using InfluxDB OSS, seemed like the most obvious choice. This was my initial intent. What
stopped me short of doing this is the lack of an InfluxDB version &amp;gt;=2.0 available for my
rpi3B+ architecture (armv7l). If I had a spare rpi4 lying around, this would have been
my choice. I do have InfluxDB version 1.8.6-1 available in my repo:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;influxdb/unknown,now 1.8.6-1 armhf
  Distributed time-series database.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This version will allow me to query with both the legacy InfluxQL query language and
Flux if I toggle that option within the configuration. But, I cannot write to the
time-series database using Flux. I do not like the idea of being locked into the
older version of InfluxDB and therefore, I chose postgres as my storage solution.&lt;/p&gt;

&lt;h4 id=&quot;a-glimpse-of-the-raw-data&quot;&gt;A glimpse of the raw data&lt;/h4&gt;

&lt;p&gt;The screenshot below was taken from InfluxData’s GUI &lt;strong&gt;Data Explorer&lt;/strong&gt;. A few items to note. I did not
aggregate the data. I take samples from my daughter’s pulse oximeter once a second. This is the same
resolution I store in the cloud. The start time is the starting timeframe of the query (now() - 10s) in this
case. The stop time is/was now(). The time column is the actual time of the sensor read. The value
column is the sensor reading itself and is paired with the field column. The field in time-series lingo is
an un-indexed column. The measurement column is analogous to the table name in a relational database which in this
case is spo2 (not the best choice and I should have named it differently). Finally, UID is a tag or an
indexed column. This is residual from me experimenting with multiple sensors and completely lacks
any information or utility at this point-in-time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/streaming_tables.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The sensor reads are all stored to InfluxDB in UTC time. I plan on doing the same for my postgresql instance.
From my experience, timestamps can cause some real headaches and the clearest path is to store in UTC time
and to handle any timezones on the application end while modeling.&lt;/p&gt;

&lt;h4 id=&quot;etl-script&quot;&gt;ETL Script&lt;/h4&gt;

&lt;p&gt;So, a brief outline of what the script should do:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create a time range/constraint of one hour since I will be taking snapshots every hour of everyday&lt;/li&gt;
  &lt;li&gt;Query InfluxDB using those created time constraints&lt;/li&gt;
  &lt;li&gt;Handle as much of the transformation as I can during the query, e.g. Aggregate, Pivot and Drop columns&lt;/li&gt;
  &lt;li&gt;Save query return to pandas dataframe&lt;/li&gt;
  &lt;li&gt;Drop final un-wanted columns, convert timestamp into datetime64 and make dttm an index&lt;/li&gt;
  &lt;li&gt;Push dataframe to postgresql instance, appending onto table if it exists&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This script will only execute once, therefore, since I am taking one hour snapshots, I need
to schedule the script to execute once per hour. More on that shortly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Filename: health_metrics_loader.py
# Author:   Mike Hinkle
# Purpose:  Extract data from InfluxDB cloud account, sanitize 
#           and push to local postgres instance
&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;influxdb_client&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InfluxDBClient&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sqlalchemy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dotenv&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dotenv&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timedelta&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;load_dotenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Load secrets from dotenv file
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TOKEN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;TOKEN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ORG&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ORG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CONNECTION&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PG_CONNECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PG_CONNECT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Create time range to bound query
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utcnow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%Y-%m-%dT%H:00:00Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utcnow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timedelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hours&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;last_hour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%Y-%m-%dT%H:00:00Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Instantiate connection object for TSDB
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InfluxDBClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TOKEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ORG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query_api&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_api&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Query InfluxDB cloud instance and return in df
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query_api&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_data_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'from(bucket: &quot;pulse_oximeter&quot;) '&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;|&amp;gt; range(start: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_hour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, stop: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;) &quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'|&amp;gt; filter(fn: (r) =&amp;gt; r._measurement == &quot;spo2&quot;) '&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;|&amp;gt; aggregateWindow(every: 5s, fn: mean, createEmpty: false)&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'|&amp;gt; drop(columns: [&quot;_start&quot;,&quot;_stop&quot;,&quot;_measurement&quot;,&quot;uid&quot;])'&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'|&amp;gt; pivot(rowKey:[&quot;_time&quot;], columnKey: [&quot;_field&quot;], valueColumn: &quot;_value&quot;)'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#
# Close connection object
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__del__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Drop don't care columns, rename time header and set time as index
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;table&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;result&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;datetime64[us]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Instantiate sqlalchemy connection object
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PG_CONNECT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Use pandas to write dataframe to postgres instance
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_current_sats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pox_five_second_mean&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if_exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;append&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#
# Close sqlalchemy connection object
#
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dispose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scheduling-considerations&quot;&gt;Scheduling considerations&lt;/h3&gt;

&lt;p&gt;Now that the script is complete, and I know that it works, I need to
ensure that it is run once per hour. The path of least resistence since
I am running a single script on the same raspberry hosting the postgresql
server, will be to run the script as a cronjob. I realize that there
are more robust scheduling solutions such as &lt;strong&gt;Apache Airflow&lt;/strong&gt; and I
intend to do the same with a DAG (Directed Acyclic Graph) at a later date.
For now, I want to get the data collected and I do not have airflow
installed on the rpi3b+. So, forgive my rush and the simplicity of
the solution.&lt;/p&gt;

&lt;p&gt;After pushing the script to the raspberry pi 3b+, installing the
dependencies (python-dotenv, psycopg2, sqlalchemy, influxdb-client and
pandas) and creating my .env file containing my secrets, I can create the cronjob
like so:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pi@influxdb-historic:~ &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;crontab &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/bin/python3 /home/pi/pg_loader/health_metrics_loader.py &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/cron.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That should do the trick. I will check later tonight, plug my new postgres instance
into my Grafana install running on my workstation and see if the data
is collecting successfully.&lt;/p&gt;

&lt;h3 id=&quot;8-hours-later-update&quot;&gt;8-hours later (Update)&lt;/h3&gt;

&lt;p&gt;It looks like the script and the cronjob were a success:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/grafana_historic.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I will be revisiting this project to discuss various models when I have ample
historical data. I might also redo the scheduling using Apache Airflow. I am hesitant
since it seems like bird hunting with a scud missle and slightly overkill.
If you see any opportunities for improvements or mistakes, please shoot me an 
email. Thank you for reading and for your time.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Questions give us no rest.”
― Ayn Rand&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Mike Hinkle</name></author><category term="rpi" /><category term="influxdb" /><category term="postgresql" /><category term="etl" /><category term="cronjob" /><summary type="html">Quick Recap</summary></entry><entry><title type="html">RPI3b+ (Headless) running PostgreSQL instance on localhost for longer term data retention (Part 1)</title><link href="http://localhost:4000/rpi/headless/postgresql/2021/07/10/rpi_headless_postgres.html" rel="alternate" type="text/html" title="RPI3b+ (Headless) running PostgreSQL instance on localhost for longer term data retention (Part 1)" /><published>2021-07-10T17:00:00+02:00</published><updated>2021-07-10T17:00:00+02:00</updated><id>http://localhost:4000/rpi/headless/postgresql/2021/07/10/rpi_headless_postgres</id><content type="html" xml:base="http://localhost:4000/rpi/headless/postgresql/2021/07/10/rpi_headless_postgres.html">&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;I have been collecting my daughter’s pulse oximeter data for almost two years. She is
24-hour ventilator dependent and my wife and I have had some close calls where she has stopped 
breathing. Initially, the only way we could see her sats was to be physically in front of the 
pulse oximeter. Obviously, this is not a realistic option. Over the last few years, I have
attemped different solutions to not only monitor her, but also to model her breathing and
various health metrics. Some of those solutions were:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;php scripts through apache on a local server&lt;/li&gt;
  &lt;li&gt;InfluxDB also on a local server and plugged into Grafana for visualization&lt;/li&gt;
  &lt;li&gt;InfluxDB Cloud, which enabled us to monitor her remotely&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I still use number 3 above to this very day:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/mobile_web_grafana.jpg&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Full disclosure, I am cheap and use the hobbyist free account for both InfluxDB and Grafana which understandably 
comes with some limitations. One of those limitations is a 30-day data retention policy for InfluxDB. 30-days is 
great for real time monitoring, but what if I want to model seasonal patterns year-on-year? This is
the spirit of this project. I want to capture as much historical data as possible without spending
any money. I already have a spare raspberry pi 3b+ and I have an internet connection, what more do I need?&lt;/p&gt;

&lt;p&gt;Covered in this write-up today will be:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Downloading Raspberry Pi OS and flashing the OS to a microSD&lt;/li&gt;
  &lt;li&gt;Activating SSH and the WIFI connection to run headless&lt;/li&gt;
  &lt;li&gt;Remotely logging into pi to bring the system up-to-date&lt;/li&gt;
  &lt;li&gt;Downloading and configuring postgreSQL&lt;/li&gt;
  &lt;li&gt;Testing that configuration&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Part 2 of this series will actually extract the data I have in my InfluxDB Cloud instance using the Flux query language, 
shape the data and push the desired data to the postgreSQL instance I will be creating today. So, let us begin…&lt;/p&gt;

&lt;h3 id=&quot;downloading-raspberry-pi-os-and-flashing-the-os-to-a-microsd-card&quot;&gt;Downloading raspberry pi OS and flashing the OS to a microSD card&lt;/h3&gt;

&lt;p&gt;I have been using raspberry pi’s for years and I cannot emphasize enough, how great they are for the price. Once ordering
a board which typically costs me ~35$ US, I need to download an OS and flash that OS to a microSD card.
Since I am looking to do this quickly, I am not installing anything cute like Arch or Gentoo. Raspberry Pi OS it is. The images can be
downloaded here: &lt;a href=&quot;https://www.raspberrypi.org/software/operating-systems/&quot;&gt;OS Download&lt;/a&gt;. You will find multiple versions,
in my case since I am configuring this single board computer to run headless, I do not need a GUI or any additional
software (like LibreOffice, etc..) so I selected Raspberry Pi OS Lite.&lt;/p&gt;

&lt;p&gt;Once the OS is downloaded, I change into the directory where the download was saved (in my case ~/Downloads/) and I unzip the 
image using the following command: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ unzip 2021-05-07-raspios-buster-armhf-lite.zip&lt;/code&gt; which will uncompress a single
image. In  my case, the image was named &lt;strong&gt;2021-05-07-raspios-buster-armhf-lite.img&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;At this stage, for the past few years, I have used balenaEtcher to flash images to microSDs: &lt;a href=&quot;https://www.balena.io/etcher/&quot;&gt;Balena Download&lt;/a&gt;,
I have never had any issues and the software works wonderfully. Today however, I wanted to try out a USB flashed I have resident
on my OS which comes installed on POP!_OS named &lt;strong&gt;Popsicle&lt;/strong&gt;.:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/popsicle_screenshot.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once the image was selected and pointed at my microSD card, I can proceed to burn the image. If I was hooking the raspberry pi
up to a monitor and keyboard after the image was burned, I could go ahead and install the microSD card into my raspberry pi
and skip the next section below. But, since I do not have an extra monitor and want to run headless, I will be adding a
few extra files to the microSD card before I remove the microSD card from my workstation.&lt;/p&gt;

&lt;h3 id=&quot;activating-ssh-and-wifi-connection-to-run-headless&quot;&gt;Activating SSH and WIFI connection to run headless&lt;/h3&gt;

&lt;p&gt;To avoid needing a monitor and a keyboard for my rpi and to make the single board computer available online to access
via SSH, I need to add 2 files to the root of /boot on the newly installed image. On my workstation, once the microSD is
mounted to my filesystem, I can change directory into /boot (the microSD card is mounted for me at /media/run/),
and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;touch ssh&lt;/code&gt;, this will create an empty file named &lt;strong&gt;ssh&lt;/strong&gt; which enables ssh. The second file I need to create will be named &lt;strong&gt;wpa_supplicant.conf&lt;/strong&gt; and it should be located
in the same directory, I just created the empty ssh file. The contents of this file are:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;country=FR
ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
update_config=1

network={
    ssid=&quot;NAME-OF-YOUR-WIFI-NETWORK&quot;
    psk=&quot;PASSWORD-FOR-YOUR-WIFI&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I can save and close the above file and I am done. The microSD card can be unmounted, ejected and installed
into my raspberry pi. Once the raspberry pi is plugged into a 5V power supply, and I am within range
of my wifi, I should be able to ssh in using my workstation.&lt;/p&gt;

&lt;h3 id=&quot;remotely-logging-into-pi-to-bring-the-system-up-to-date&quot;&gt;Remotely logging into pi to bring the system up-to-date&lt;/h3&gt;

&lt;p&gt;Once my pi is plugged in and out of the way, I can use &lt;strong&gt;nmap&lt;/strong&gt; from my workstation to find out
which ip address my rpi was assigned. But, first I need my inet ip address:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ifconfig

wlp5s0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt;  mtu 1500
    inet 192.168.0.28  netmask 255.255.255.0  broadcast 192.168.0.255
    inet6 2a01:e0a:897:1680:4e48:5fa5:da96:558c  prefixlen 64  scopeid 0x0&amp;lt;global&amp;gt;
    inet6 2a01:e0a:897:1680:19f8:90c1:6834:f9e6  prefixlen 64  scopeid 0x0&amp;lt;global&amp;gt;
    inet6 fe80::3e7d:52b9:f37d:b024  prefixlen 64  scopeid 0x20&amp;lt;link&amp;gt;
    ether 74:d8:3e:01:6d:14  txqueuelen 1000  (Ethernet)
    RX packets 66847  bytes 50766070 (50.7 MB)
    RX errors 0  dropped 36  overruns 0  frame 0
    TX packets 46905  bytes 9180586 (9.1 MB)
    TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The relevant ip address above is &lt;strong&gt;192.168.0.28&lt;/strong&gt;. Armed with this, I can now use
nmap to determine my rpi’s address:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo nmap -sn 192.168.0.28/24

Starting Nmap 7.80 ( https://nmap.org ) at 2021-07-10 14:58 CEST
Nmap scan report for 192.168.0.12 
Host is up (0.25s latency).
MAC Address: B8:27:EB:E0:08:FB (Raspberry Pi Foundation)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, I can access my rpi remotely via ssh using the ip address &lt;strong&gt;192.168.0.12&lt;/strong&gt;. 
Please note that the default password for raspberry’s is &lt;em&gt;raspberry&lt;/em&gt; so enter that
when prompted:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh pi@192.168.0.12

pi@192.168.0.12's password: 
Linux influxdb-historic 5.10.17-v7+ #1421 SMP Thu May 27 13:59:01 BST 2021 armv7l

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Sat Jul 10 12:27:06 2021 from 192.168.0.28
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please note that I have logged in already prior to this so your output my be slightly different.
The first thing I did was to change the password from raspberry to a password of my choice. To
do this, type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;passwd&lt;/code&gt; and then type enter. You could also type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;passwd pi&lt;/code&gt; and then enter. 
Follow the prompts to update the password.&lt;/p&gt;

&lt;p&gt;After this is complete, I like to change the keyboard and language settings using
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo raspi-config&lt;/code&gt;. Once all the settings are to my liking, I save and restart the pi:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo reboot&lt;/code&gt;. That will kick me off ssh and terminate my connection. After a minute or
so, I can re-connect via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh pi@192.168.0.12&lt;/code&gt;, enter my new password and once logged in,
continue to update my packages from the repo with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo apt update &amp;amp;&amp;amp; sudo apt upgrade&lt;/code&gt;.
That’s it, for this section, next step will be downloading and configuring the postgresql
server.&lt;/p&gt;

&lt;h3 id=&quot;downloading-and-configuring-the-postgresql-database-server&quot;&gt;Downloading and configuring the PostgreSQL Database Server&lt;/h3&gt;

&lt;p&gt;If you are un-familiar with databases, PostgreSQL is considered a RDBMS or
&lt;strong&gt;R&lt;/strong&gt;elational &lt;strong&gt;D&lt;/strong&gt;atabase &lt;strong&gt;M&lt;/strong&gt;anagement &lt;strong&gt;S&lt;/strong&gt;ystem and is in a nutshell, an excellent place to store 
relational data. In a corporate setting I was more familiar with Oracle, but PostgreSQL is essentially 
the same thing for zero cost (which I would argue makes it better than Oracle :stuck_out_tongue_winking_eye:).
Anyway, moving on… Let’s install it:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ apt search postgresql

postgresql/stable,now 11+200+deb10u4 all
  object-relational SQL database (supported version)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above command is used to search through the default system repos. There will be many items returned,
but the package I would like to install is the supported version seen above.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt install postgresql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After this is complete, you can check to see if the database server is running:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ systemctl status postgresql

● postgresql.service - PostgreSQL RDBMS
   Loaded: loaded (/lib/systemd/system/postgresql.service; enabled; vendor preset: enabled)
   Active: active (exited) since Sat 2021-07-10 12:50:01 CEST; 2h 57min ago
  Process: 7771 ExecStart=/bin/true (code=exited, status=0/SUCCESS)
 Main PID: 7771 (code=exited, status=0/SUCCESS)

Jul 10 12:50:01 influxdb-historic systemd[1]: Starting PostgreSQL RDBMS...
Jul 10 12:50:01 influxdb-historic systemd[1]: Started PostgreSQL RDBMS.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I didn’t see this above, I would need to start the service myself. Also, if I would like
the postgres database to start at boot, then I would need to enable it (assuming systemd):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo systemctl start postgresql
$ sudo systemctl enable postgresql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, now postgreSQL is installed and running in the background. I can login into the database
but need to switch to the postgres user first:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo su - postgres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now to connect through CLI using the postgresql-client:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;postgres@influxdb-historic:~$ psql
psql (11.12 (Raspbian 11.12-0+deb10u1))
Type &quot;help&quot; for help.

postgres=#
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And it was a success. I typically create a new user at this point with a password. This
user I am creating will be the owner of my historical data database.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;postgres=# CREATE USER soitgoes511 WITH PASSWORD '&amp;lt;YOUR_PASSWORD_HERE&amp;gt;';
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, I want to create my database and change the ownership to the new user I created:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;postgres=# CREATE DATABASE pulse_oximeter_historic;
postgres=# ALTER DATABASE pulse_oximeter_historic OWNER TO soitgoes511;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I can see my new database owned by yours truly:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;postgres=# \l
                                          List of databases
          Name           |    Owner    | Encoding |   Collate   |    Ctype    |   Access privileges   
-------------------------+-------------+----------+-------------+-------------+-----------------------
 postgres                | postgres    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 
 pulse_oximeter_historic | soitgoes511 | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 
 template0               | postgres    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
                         |             |          |             |             | postgres=CTc/postgres
 template1               | postgres    | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
                         |             |          |             |             | postgres=CTc/postgres
(4 rows)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;test-database-by-writing-to-it-remotely&quot;&gt;Test database by writing to it remotely&lt;/h3&gt;

&lt;p&gt;Before testing, I need to make a a few changes to some of the postgreSQL configuration files. The loader I will
be writing to populate this database with historical data will most likely run locally (on the pi), but I will be testing
from my workstation. Therefore, I need to give authorization for my ip address to connect to the db and I
need to the database to listen for more than the localhost. I will also be accessing the database to query data for modeling
eventually and will need to ensure that I can access it:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo vim /etc/postgresql/11/main/postgresql.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First, I uncomment and change this line under &lt;em&gt;connections and authentication&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;listen_addresses = '*'                  # what IP address(es) to listen on;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Save and close. Then I can open up &lt;strong&gt;pg_hba.conf&lt;/strong&gt; and give permissions to my workstation to connect:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo vim /etc/postgresql/11/main/pg_hba.conf

host    all             all             192.168.0.28/32         trust
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once this line is appended, I can restart my postgresql server and attempt to write some data to it:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo systemctl restart postgresql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From my workstation, I am using a &lt;strong&gt;jupyter-notebook&lt;/strong&gt; and python 3 to first test the remote connection and
then to load a dummy dataset I downloaded as a csv file off &lt;strong&gt;Kaggle&lt;/strong&gt;. Here is a screenshot of those scripts
and the output:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;psycopg2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;conn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;psycopg2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;192.168.0.12&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;pulse_oximeter_historic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;soitgoes511&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;YOUR_PSQL_PASSWORD&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create a cursor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cursor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# execute a statement
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PostgreSQL database version:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SELECT version()&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# display the PostgreSQL database server version
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db_version&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fetchone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db_version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# close the communication with the PostgreSQL
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The connection was successful. OUTPUT:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PostgreSQL database version:
('PostgreSQL 11.12 (Raspbian 11.12-0+deb10u1) on arm-unknown-linux-gnueabihf, compiled by gcc (Raspbian 8.3.0-6+rpi1) 8.3.0, 32-bit',)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let me attempt to write some data to the db:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sqlalchemy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;postgresql://soitgoes511:&amp;lt;YOUR_PSQL_PASSWORD&amp;gt;@192.168.0.12:5432/pulse_oximeter_historic&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_best_sellers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/home/soitgoes/Kaggle/bestsellers_with_categories.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df_best_sellers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bestsellers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if_exists&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;replace&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dispose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, to sanity check the data made it there, let me query it:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sqlalchemy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;postgresql://soitgoes511:&amp;lt;YOUR_PSQL_PASSWORD&amp;gt;@192.168.0.12:5432/pulse_oximeter_historic&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;SELECT * FROM bestsellers LIMIT 5;&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dispose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/dummy_table.png&quot; alt=&quot;drawing&quot; style=&quot;max-width: 100%; height: auto; text-align: center;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It worked :sparkles:. That is a wrap for today. Part II as I mentioned will delve into actually extracting the relevant
data, transforming/shaping it and then loading it into my new postgres instance hosted on my very cheap and
wonderful rpi3b+. Thank you for reading.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I think, at a child’s birth, if a mother could ask a fairy godmother to endow it with the most useful gift, that gift would be curiosity.”
― Eleanor Roosevelt&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Mike Hinkle</name></author><category term="rpi" /><category term="headless" /><category term="postgresql" /><summary type="html">Motivation</summary></entry><entry><title type="html">Broken virtual environments: Why it happened and how I should have prevented it</title><link href="http://localhost:4000/linux/update/python/venv/broken/prevention/2021/07/06/fixing_broken_venv.html" rel="alternate" type="text/html" title="Broken virtual environments: Why it happened and how I should have prevented it" /><published>2021-07-06T17:00:00+02:00</published><updated>2021-07-06T17:00:00+02:00</updated><id>http://localhost:4000/linux/update/python/venv/broken/prevention/2021/07/06/fixing_broken_venv</id><content type="html" xml:base="http://localhost:4000/linux/update/python/venv/broken/prevention/2021/07/06/fixing_broken_venv.html">&lt;p&gt;Approximately 3-4 days ago, I updated my Linux box (&lt;strong&gt;Pop!_OS&lt;/strong&gt; version 20.10 -&amp;gt; 21.04). 
I have run Linux long enough to know that there could be unintended issues during
these major version updates. My first defense against possible headaches is to wait for
a few days and hope others find the bugs, report them and everything gets ironed out quickly.
Years ago I was not as cautious :see_no_evil:, but I no longer have the luxury of time to bang my head
into a desk for days and slog through issues or re-compile kernels. I just play it safe now.&lt;/p&gt;

&lt;p&gt;The good news is that despite a drastic change to the Pop!_OS desktop environment
(from &lt;strong&gt;GNOME 3.38.4&lt;/strong&gt; to &lt;strong&gt;COSMIC&lt;/strong&gt;), the update and upgrade went very smoothly. The new DE
is an improvement on GNOME, my system is very responsive, the stars all aligned and
everything is perfect. Kudos to the system76 team :thumbsup:. But.. Not everything
was perfect…&lt;/p&gt;

&lt;h3 id=&quot;what-exactly-was-the-problem&quot;&gt;What exactly was the problem?&lt;/h3&gt;

&lt;p&gt;Let me begin by saying that my issue has nothing to do with my updated OS. I decided
yesterday that I wanted to update a Heroku application which lives in a local repository
on my now updated workstation. This application was written in Python and the interpreter executed within a 
virtual environment (venv). Virtual environments should be self contained, correct? 
Sounds safe right :skull:? What happened was that the OS upgrade replaced my pre-existing system python (3.8) with
a newer python version (3.9). Had I sourced a standalone python install when creating the
virtual environment, or had the OS just switched PYTHON_TARGETS, then I would not be
writing this right now. I had created the venv like so for this particular Heroku application:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;soitgoes@pop-os:~$ python3 -m venv venv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The above command created said virtual environment inside a directory called venv with a symbolic link
pointing from the venv interpreter to my system python interpreter @ /usr/bin/python3.8 which no longer existed :disappointed::&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lrwxrwxrwx 1 soitgoes soitgoes    6 Jun 17 21:38 python3.8 -&amp;gt; python&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;At my previous work, I had many python versions installed on a dev mount to avoid this very issue.&lt;/p&gt;

&lt;h3 id=&quot;how-to-fix-the-issue-and-my-steps-moving-forward-&quot;&gt;How to fix the issue and my steps moving forward …&lt;/h3&gt;

&lt;p&gt;Install a standalone development python which lives seperately and isolated from my system python. This
would avoid the pain I am enduring now when my system is updated again with a new python install. 
I have no excuse for dropping the ball like this but it is what it is. Lesson learned.
Steps to remedy the situation, starting with that isolated python install:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download desired python version &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ wget https://www.python.org/ftp/python/3.8.11/Python-3&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Uncompress the python version   &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ tar -xzvf Python-3.8.11.tgz&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Change into directory           &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ cd Python-3.8.11/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Configure with target location  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ ./configure --prefix=/home/soitgoes/python-3.8.11&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Compile and build               &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ make&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Test build                      &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ make test&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Install python to target location  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ make altinstall&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I can see that the above steps were successful by executing the newly installed
interpreter which was specified in my target location above (/home/soitgoes/python-3.8.11)
:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;soitgoes@pop-os:~$ ~/python-3.8.11/bin/python3.8&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And voilà… The REPL (&lt;strong&gt;R&lt;/strong&gt;ead, &lt;strong&gt;E&lt;/strong&gt;valuate, &lt;strong&gt;P&lt;/strong&gt;rint, &lt;strong&gt;L&lt;/strong&gt;oop) prompt appears reflecting
my desired version:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Python 3.8.11 (default, Jul  6 2021, 22:44:39)
[GCC 10.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My system python has been unchanged and I can verify this very easily:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;soitgoes@pop-os:~$ which python3
/usr/bin/python3
soitgoes@pop-os:~$ python3
Python 3.9.5 (default, May 11 2021, 08:20:37)
[GCC 10.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please notice the versioning differences. The next step in this process will be to
rebuild the symbolic links in the affected virtual environment. Please make note that
the python3 symlink points to the system /usr/bin/python3 (which is the issue since it
is now python 3.9 rather than 3.8). The other symlinks just chain all the python 
aliases together: python -&amp;gt; python3 which I just mentioned points to the system python
install. Finally, the last link is python3.9 -&amp;gt; python3 again:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lrwxrwxrwx 1 soitgoes soitgoes    7 Jul  4 22:58 python -&amp;gt; python3
lrwxrwxrwx 1 soitgoes soitgoes   16 Jul  4 22:58 python3 -&amp;gt; /usr/bin/python3
lrwxrwxrwx 1 soitgoes soitgoes    7 Jul  4 22:58 python3.9 -&amp;gt; python3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These soft links need to be re-directed to my newly built and installed python which
is now located in my home directory. I can do this simply by changing into the affected
venv/bin/ directory where the symlinks are present and then:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$ ln -sf /home/soitgoes/python-3.8.11/bin/python3.8 python3&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The symlinks are now corrected. When activating the previously affected venv, and
running the python interpreter I am greeted with version 3.8.11 rather than 3.9.5.
My application will again run without the need of rebuilding all of my dependencies.
Since this is fixed and it is getting late, I will need to actually do what I set out
to do initially (update my Heroku app) later. Enough problems solved for one day.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The moral of the story is to ensure you seperate your system dependencies from your
development dependencies. No sense in muddying the waters and causing unnecessary
headaches.&lt;/strong&gt; :heavy_check_mark:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The mind is not a vessel to be filled, but a fire to be kindled.
&lt;em&gt;― Plutarch&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Mike Hinkle</name></author><category term="linux" /><category term="update" /><category term="python" /><category term="venv" /><category term="broken" /><category term="prevention" /><summary type="html">Approximately 3-4 days ago, I updated my Linux box (Pop!_OS version 20.10 -&amp;gt; 21.04). I have run Linux long enough to know that there could be unintended issues during these major version updates. My first defense against possible headaches is to wait for a few days and hope others find the bugs, report them and everything gets ironed out quickly. Years ago I was not as cautious :see_no_evil:, but I no longer have the luxury of time to bang my head into a desk for days and slog through issues or re-compile kernels. I just play it safe now.</summary></entry><entry><title type="html">Initial observations while settling in</title><link href="http://localhost:4000/france/blog/careers/ee/2021/06/26/initial_observations.html" rel="alternate" type="text/html" title="Initial observations while settling in" /><published>2021-06-26T17:00:00+02:00</published><updated>2021-06-26T17:00:00+02:00</updated><id>http://localhost:4000/france/blog/careers/ee/2021/06/26/initial_observations</id><content type="html" xml:base="http://localhost:4000/france/blog/careers/ee/2021/06/26/initial_observations.html">&lt;p&gt;I have begun applying for jobs. Perhaps I am being un-realistic considering
I am a beginner in the French language. I could not imagine finding a job in
the states and not speaking English. :crossed_fingers:&lt;/p&gt;

&lt;h3 id=&quot;some-observations-&quot;&gt;Some observations …&lt;/h3&gt;

&lt;p&gt;My first observation is that most positions in the fields I am looking for are
looking for Master’s or PHd’s. I guess when university doesn’t cost $100k for
an undergraduate degree :moneybag:, there is more motivation to go a step further. I find myself
regretting not sticking it out for my Master’s but that ship has sailed. At least
I have experience in industry.&lt;/p&gt;

&lt;p&gt;My second observation is that Electrical Engineering degrees here do not translate
to the same studies in the US. I could be wrong and I will have a better perspective
on this very shortly. I have noticed quite a bit of variation in EE degrees in the US, 
too. I have friends which never studied transistors at their schools. We were drowned in
small signal models, large signal models, BJT’s, MOSFET’s, etc.. After long
discussions with my wife in the past, my understanding is that the French University
system is, for the most part, standardized.&lt;/p&gt;

&lt;p&gt;Due to the second observation above :point_up:, there will probably be some
ambiguity for potential employers. I am attempting to find a career in big data,
data science, data engineering, analytics, web development, etc.. Not sure if that
aligns even remotely with what their EE’s learn at University, but it is not a huge
leap from my past curriculum and studies. Only time will tell. It has only been
2 weeks since I set foot on French soil and I need to be patient and keep plugging away.
On the bright side, in the meantime, I can spend time with my family. I never would 
have had this much time with my children had we stayed in the US.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Per aspera ad astra&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Mike Hinkle</name></author><category term="france" /><category term="blog" /><category term="careers" /><category term="EE" /><summary type="html">I have begun applying for jobs. Perhaps I am being un-realistic considering I am a beginner in the French language. I could not imagine finding a job in the states and not speaking English. :crossed_fingers:</summary></entry><entry><title type="html">A new start in France</title><link href="http://localhost:4000/first/france/blog/careers/family/2021/06/21/new_start_in_france.html" rel="alternate" type="text/html" title="A new start in France" /><published>2021-06-21T16:01:00+02:00</published><updated>2021-06-21T16:01:00+02:00</updated><id>http://localhost:4000/first/france/blog/careers/family/2021/06/21/new_start_in_france</id><content type="html" xml:base="http://localhost:4000/first/france/blog/careers/family/2021/06/21/new_start_in_france.html">&lt;p&gt;I will keep this short and sweet. I left corporate life in &lt;strong&gt;America&lt;/strong&gt; to move to my wife’s home country, &lt;strong&gt;France&lt;/strong&gt;. I had worked in the &lt;em&gt;semiconductor industry&lt;/em&gt; for about 4 years as 
an &lt;em&gt;engineer&lt;/em&gt; in various roles. My background at University was &lt;strong&gt;Electrical Engineering&lt;/strong&gt; with a concentration in microelectronics. My employer treated me well and finances were good. 
I had a real career. About 3.5 years ago my beautiful daughter was born. My wife and I were informed at our 20 week sonogram that there were issues. Our life has never been the same 
since.&lt;/p&gt;

&lt;p&gt;I have been through plenty of hard times in my life, but to this day, seeing her struggles has really darkened my soul. We came to France so her and my son could be with family. We
came to France so they could be loved. We are only here on this earth for a brief moment and like &lt;em&gt;Bob Marley&lt;/em&gt; said so wonderfully:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“…life is worth much more than gold.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is my first blog entry. I promise that I will delve into some fun projects down the road. I am waiting until we purchase our house to nerd out on some &lt;strong&gt;IOT and pub-sub messaging
systems&lt;/strong&gt;. If you read this, thank you. :grin:&lt;/p&gt;

&lt;div style=&quot;display: inline-block;&quot;&gt;
  &lt;img src=&quot;/assets/baby_girl_1.jpeg&quot; alt=&quot;drawing&quot; style=&quot;height: 300px;&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;display: inline-block;&quot;&gt;
  &lt;img src=&quot;/assets/french_town_1.jpg&quot; alt=&quot;drawing&quot; style=&quot;height: 300px;&quot; /&gt;
&lt;/div&gt;
&lt;div style=&quot;display: inline-block;&quot;&gt;
  &lt;img src=&quot;/assets/baby_boy_1.jpeg&quot; alt=&quot;drawing&quot; style=&quot;height: 300px;&quot; /&gt;
&lt;/div&gt;</content><author><name>Mike Hinkle</name></author><category term="first" /><category term="france" /><category term="blog" /><category term="careers" /><category term="family" /><summary type="html">I will keep this short and sweet. I left corporate life in America to move to my wife’s home country, France. I had worked in the semiconductor industry for about 4 years as an engineer in various roles. My background at University was Electrical Engineering with a concentration in microelectronics. My employer treated me well and finances were good. I had a real career. About 3.5 years ago my beautiful daughter was born. My wife and I were informed at our 20 week sonogram that there were issues. Our life has never been the same since.</summary></entry></feed>